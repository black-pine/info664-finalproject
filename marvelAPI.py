# This file reads from "marvelData.xlsx" (generated by "calculateMarvel.py") located in the same directory as this file
# This file requires API keys for the Marvel API (https://developer.marvel.com/) on lines 22 & 23
# This file uses issues saved in "marvelData.xlsx" to query the Marvel API
# This file generates .JSON files saved in a 'records' folder located in the same directory as this file


import requests
import re
import json
from openpyxl import load_workbook
import hashlib
import time

# pulling title name from title field
# Group 1 = title
# Group 2 = year
# Group 3 = additional title content (optional)
titlePattern = re.compile(r'(.*)\s\((\d*)\)(.*)')

baseURL = 'https://gateway.marvel.com/'
reqURL = baseURL + '/v1/public/comics'
pubkey = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx' # PUBLIC API KEY: REQUIRED
pvtkey = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx' # PRIVATE API KEY: REQUIRED
ts = time.time()
hashval = f"{ts}{pvtkey}{pubkey}"
hashkey = hashlib.md5(hashval.encode()).hexdigest()

paramDiamond = {
	'apikey': pubkey,
	'hash': hashkey,
	'ts': ts,
	'noVariants': 'true',
	'diamondCode': ''
}
paramTitle = {
	'apikey': pubkey,
	'hash': hashkey,
	'ts': ts,
	'noVariants': 'true',
	'orderBy': 'onsaleDate',
	'title': '',
	'issueNumber': ''
}

wb = load_workbook('marvelData.xlsx')

for year in range(2003, 2021):
	for month in range(1, 13):
		# adjustments to get only range [3/2003, 3/2020]
		if year == 2003 and month < 3:
			continue
		if year == 2020 and month > 3:
			break

		sheet = wb[f"{year}_{month}"]
		# create a column to save the marvel id number
		sheet['N1'] = 'marvel id'
		for row in range(2, 6):
			# try searching Marvel API by Diamond Code
			paramDiamond['diamondCode'] = sheet.cell(row = row, column = 6).value
			req = requests.get(reqURL, params=paramDiamond)
			data = json.loads(req.text)

			# try searching by title & issue number if diamond code is not listed in API
			if data['code'] == 200 and data['data']['total'] == 0:
				# use regex to separate title text and date
				titleSections = titlePattern.search(sheet.cell(row = row, column = 9).value)
				paramTitle['title'] = titleSections.group(1)
				if titleSections.group(3):
					paramTitle['title'] += ' ' + titleSections.group(3)
				paramTitle['issueNumber'] = sheet.cell(row = row, column = 10).value
				req = requests.get(reqURL, params=paramTitle)
				data = json.loads(req.text)

			# save results as individual files
			if data['code'] == 200:
				# expecting a single result, but if multiple issues are returned try to filter by date
				if data['data']['total'] != 1:
					for comic in data['data']['results']:
						for date in comic['dates']:
							try:
								# save file if the dates match
								if date['type'] == 'onsaleDate' and (date['date'].startswith(str(year)) or date['date'].startswith(titleSections.group(2))):
									filename = f"{comic['id']}.json"
									json.dump(comic, open('records/'+filename, 'w'), indent=4)
									sheet.cell(row = row, column = 14).value = comic['id']
							except:
								continue
				else:
					for comic in data['data']['results']:
						filename = f"{comic['id']}.json"
						json.dump(comic, open('records/'+filename, 'w'), indent=4)
						sheet.cell(row = row, column = 14).value = comic['id']

wb.save('marvelData.xlsx')